{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Digital Signal Processing Courseware: An Introduction (copyright © 2024)\n",
    "## Authors: J. Christopher Edgar and Gregory A. Miller\n",
    "\n",
    "Originally written in Mathematica by J. Christopher Edgar. Conversion to Jupyter Notebook by Song Liu.\n",
    "\n",
    "The authors of this courseware are indebted to Prof. Bruce Carpenter (University of Illinois Urbana-Champaign). Bruce inspired the creation of this courseware, he consulted with the authors as this courseware was being developed, and he provided the original version of the code and text for several sections of this courseware (e.g. the section on complex numbers and the section on normal distributions). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=red>DSP.04 Convolution and Filtering - Spatial Domain</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=red>TUTORIALS</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image as img\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits import mplot3d\n",
    "from scipy.fft import fft, fftfreq\n",
    "import matplotlib.patches as patches\n",
    "import math\n",
    "import cmath\n",
    "import pandas as pd\n",
    "from sympy import Symbol, sin, series\n",
    "from sympy import roots, solve_poly_system\n",
    "import scipy.special\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Figure size \n",
    "plt.rc(\"figure\", figsize=(8, 6))\n",
    "\n",
    "#function to create time course figure\n",
    "#one waveform\n",
    "def make_plot_1(x1,y1,type=\"b\",linewidth = 1): \n",
    "    plt.plot(x1, y1,type)\n",
    "    plt.margins(x=0, y=0)\n",
    "    plt.axhline(y=0, color='k')\n",
    "    plt.tick_params(labelbottom = False, bottom = False)\n",
    "    \n",
    "#two overlaid waveforms with red and blue   \n",
    "def make_plot_2(x1,y1,type1,x2,y2,type2): \n",
    "    plt.plot(x1, y1, type1)\n",
    "    plt.plot(x2, y2, type2)\n",
    "    plt.margins(x=0, y=0)\n",
    "    plt.axhline(y=0, color='k')\n",
    "    plt.tick_params(labelbottom = False, bottom = False)\n",
    "    \n",
    "#three overlaid waveforms with red, blue and green   \n",
    "def make_plot_3(x1,y1,type1,x2,y2,type2,x3,y3,type3): \n",
    "    plt.plot(x1, y1, type1)\n",
    "    plt.plot(x2, y2, type2)\n",
    "    plt.plot(x3, y3, type3)\n",
    "    plt.margins(x=0, y=0)\n",
    "    plt.axhline(y=0, color='k')\n",
    "    plt.tick_params(labelbottom = False, bottom = False)\n",
    "    \n",
    "def make_plot_3d(ax,x,y,z):    \n",
    "    ax.contour3D(x, y, z, 50, cmap=cm.coolwarm)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('z')\n",
    "    \n",
    "def make_plot_freq_1(x1,sample_rate, duration=1): \n",
    "    N = sample_rate * duration\n",
    "    Nhalf = math.ceil(N/2)\n",
    "    yf = fft(x1)\n",
    "    xf = fftfreq(N, 1 / sample_rate)\n",
    "    yf = yf[0:Nhalf]\n",
    "    xf = xf[0:Nhalf]\n",
    "    plt.plot(xf, np.abs(yf))\n",
    "    \n",
    "#two spectrums\n",
    "def make_plot_freq_2(x1,x2,sample_rate, duration=1): \n",
    "    N = sample_rate * duration\n",
    "    Nhalf = math.ceil(N/2)\n",
    "    yf1 = fft(x1)\n",
    "    yf2 = fft(x2)\n",
    "    xf = fftfreq(N, 1 / sample_rate)\n",
    "\n",
    "    yf1 = yf1[0:Nhalf]\n",
    "    yf2 = yf2[0:Nhalf]\n",
    "    xf = xf[0:Nhalf]\n",
    "\n",
    "    plt.plot(xf, np.abs(yf1))\n",
    "    plt.plot(xf, np.abs(yf2), color = 'r')\n",
    "    \n",
    "def make_imshow(x):\n",
    "    plt.imshow(x,cmap='Greys_r')\n",
    "    plt.tick_params(labelbottom = False, bottom = False)\n",
    "    plt.tick_params(labelleft = False, left = False)\n",
    "    \n",
    "def make_imshow_color(x):\n",
    "    plt.imshow(x)\n",
    "    plt.tick_params(labelbottom = False, bottom = False)\n",
    "    plt.tick_params(labelleft = False, left = False)\n",
    "    \n",
    "def round_complex(x):\n",
    "    return complex(np.round(x.real,4),np.round(x.imag,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>DSP.04.T1) Filtering Spatial Images</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>DSP.B1.T1.a) Loading and Displaying Grey Scale Images Files</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first section repeats information already covered in Lesson 1. Skim through this first section and\n",
    "then move on to new material.\n",
    "\n",
    "Let's load a black-and-white image. Specifically, load in the 'statuesgreysmall.jpg' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "\n",
    "#find and select file \"statuesgreysmall.jpg\"\n",
    "file_path = filedialog.askopenfilename()\n",
    "image = img.imread(file_path)\n",
    "make_imshow(image)\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This picture was taken by David Edgar in Nassau, Bahamas. The statues are made from the trunks of trees.\n",
    "\n",
    "This greyscale image is in what is called a JPEG format. As shown above, Python knows how to\n",
    "display JPEG images. JPEG files typically have a filename extension of .jpeg or .jpg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is displayed as an image is really just a 2D matrix of numbers. Use the command below to obtain\n",
    "the numerical values used to represent this image (be patient, it may take a few seconds to generate\n",
    "the plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_flattern = np.sort(image.flatten())\n",
    "plt.plot(image_flattern)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2D matrix 'image' contains the values used to represent the image. The Python 'image.shape'\n",
    "method indicates that the image is composed of a matrix containing 742×1111 = 824362 values. This\n",
    "matrix is 742 rows by 1111 columns (notice that the width of the image (columns) is more than the\n",
    "height (rows)). The graph above shows the range of values contained in the image. As indicated on the\n",
    "y axis, the values range from 0 to 255. A '0' value represents pure black, a '255' value represents pure white,\n",
    "and the values in-between represent shades of grey. The greyscale image shown above shows a full\n",
    "range of greyscale values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>DSP.04.T1.b) Filtering a Greyscale Image</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the image again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "\n",
    "#find and select file \"statuesgreysmall.jpg\"\n",
    "file_path = filedialog.askopenfilename()\n",
    "image = img.imread(file_path)\n",
    "make_imshow(image)\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter this image. Remove high-frequency information. Start with a 2D kernel of size 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([[1/25, 1/25, 1/25, 1/25, 1/25],\n",
    "                  [1/25, 1/25, 1/25, 1/25, 1/25],\n",
    "                  [1/25, 1/25, 1/25, 1/25, 1/25],\n",
    "                  [1/25, 1/25, 1/25, 1/25, 1/25],\n",
    "                  [1/25, 1/25, 1/25, 1/25, 1/25]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolve the kernel and the image to create a filtered image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "                 \n",
    "image_filtered = signal.convolve2d(image,kernel,boundary='symm', mode='same')\n",
    "make_imshow(image_filtered)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the filtered and unfiltered image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image, cmap='Greys_r')\n",
    "make_imshow(image)\n",
    "plt.show() \n",
    "\n",
    "make_imshow(image_filtered)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What looks different? What information is missing in the filtered image?\n",
    "\n",
    "The convolution applied a moving-average filter, which we know is a low-pass filter. So, it removed some high-spatial-frequency information. In other words, we blurred the image.\n",
    "\n",
    "Try filtering the image with a larger kernel to remove more high-frequency information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "kernel = 1/81 * np.ones((9,9))                 \n",
    "image_filtered = signal.convolve2d(image,kernel,boundary='symm', mode='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the filtered and unfiltered image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image, cmap='Greys_r')\n",
    "make_imshow(image)\n",
    "plt.show() \n",
    "\n",
    "make_imshow(image_filtered)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the broad outlines remain in the filtered image. Can you think of a reason to apply a low-pass filter to your own images? Although most of us like high definition TV, why do you think some TV personalities\n",
    "are less excited about high definition TV? Do you think they might appreciate low-pass filters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>DSP.04.T1.c) In the Above Example, What Frequencies Were Removed?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout Lesson 3, and in Lesson 4 Basics, we noted what frequency (or frequencies) were\n",
    "removed when applying a kernel of a certain size. In the above example, however, when convolving the\n",
    "data with different 3D kernels, we simply noted that larger 3D kernels removed more high-frequency\n",
    "information (at the extreme, applying a kernel as large as the image, all information would be lost,\n",
    "except the mean intensity value).\n",
    "\n",
    "In the above example, why didn’t we specify which frequencies were removed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "    \n",
    "In the above example, determining what frequencies are removed is somewhat complex. To determine\n",
    "the frequencies removed given a certain kernel, we’d first need to know the (spatial) sampling rate. Assuming\n",
    "that we’re using a digital camera, the sampling rate is determined, in part, by the digital camera\n",
    "megapixel count. The word ‘pixel’ comes from “picture element”. A 1MP camera has one million pixels (i.e., one million dots). The more pixels, in general, the better\n",
    "the quality of the image (and the more expensive the camera).\n",
    "\n",
    "In addition to knowing the camera pixel count, to determine the sample rate, we need to know the size\n",
    "of the displayed or printed image. In particular, we need to know how many pixels (or dots) are used\n",
    "per unit of distance in the horizontal dimension and ditto in the vertical dimension. This depends on the image size. Generally, people talk about dots per inch (dpi) or\n",
    "pixels per inch (ppi) [or per cm, if you’re used to the metric system; 1 inche = 2.54 cm], and the more dots or pixels per inch\n",
    "the higher the quality of the image. For good-quality images, a good guideline is 300 dpi, although this\n",
    "depends a lot on what’s in the image. To achive 300 dpi for an 8\" X 10\" photo, you’d need a camera with at\n",
    "least (8 × 300) + (10 × 300) = 7,200,000 or 7.2 megapixels. Thus, for any image, to determine the effect of\n",
    "a given kernel, in addition to knowing the pixel count we need to know how densely the pixels are\n",
    "packed for some unit of distance (here, how many dots per inch)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, considering the above greyscale image, to determine what frequencies are removed when using a\n",
    "particular 3D kernel, we need to know (1) the digital camera megapixel rate and (2) the size of the\n",
    "image. In the above case, if we knew the dpi rate and the size of the image, using the procedures\n",
    "covered in the Basics, we could determine the effect of a kernel of a given size. In this courseware, instead of\n",
    "computing the above, we’ll simply qualitatively compare the image to determine whether high-frequency\n",
    "or low-frequency information is removed.\n",
    "\n",
    "The above is true for printed images. For images displayed on a video screen, the issues are more complex, since you also have to consider the\n",
    "resolution of your computer screen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>DSP.04.T2) Filtering RGB Images</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>DSP.04.T2.a) Loading and Displaying Color RGB Files</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at filtering color image. Before loading a color image, take a moment to understand an\n",
    "important aspect of many digital color images.\n",
    "\n",
    "Starting with three primary colors, these colors can be added together to produce an almost infinite\n",
    "number of other colors. Start with the primary colors of light: red, green, and blue.\n",
    "        \n",
    "With colorants such as paint and ink, the three primary colors are\n",
    "red, yellow, and blue, shaded with black and tinted with white.\n",
    "Sometime folks also consider magenta and cyan to be primary colors for colorants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circle1 = plt.Circle((0.5, 0.5), 0.4, color='r')\n",
    "\n",
    "fig, ax = plt.subplots() \n",
    "ax.add_patch(circle1)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circle2 = plt.Circle((0.5, 0.5), 0.4, color='g')\n",
    "fig, ax = plt.subplots() \n",
    "ax.add_patch(circle2)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circle3 = plt.Circle((0.5, 0.5), 0.4, color='b')\n",
    "fig, ax = plt.subplots() \n",
    "ax.add_patch(circle3)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python mixes these colors as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "\n",
    "r= random.rand()\n",
    "g= random.rand()\n",
    "b= random.rand()\n",
    "rand_color = (r, g, b)\n",
    "\n",
    "circle = plt.Circle((0.5, 0.5), 0.4, color=rand_color)\n",
    "fig, ax = plt.subplots() \n",
    "ax.add_patch(circle)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun the previous code cell many times. You can experiment with mixing your own.\n",
    "\n",
    "Whereas the colorants combine based on reflection and absorption of photons,\n",
    "RGB depends on emission of photons from a compound excited to a higher energy state by impact with an electron beam (Wikipedia).\n",
    "\n",
    "As we will see, many digital images are 'created' by recording how much red, green, and blue is needed\n",
    "at each element of the digital image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>DSP.04.T2.b) Creating a Color Image Using the RBG Color Model</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a color image. Specifically, load in the 'Augustcolor.jpg' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "\n",
    "#find and select file \"Augustcolor.jpg\"\n",
    "file_path = filedialog.askopenfilename()\n",
    "image = img.imread(file_path)\n",
    "make_imshow_color(image)\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code below to examine the numerical values used to create the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_color = image[ : , : , 0]\n",
    "green_color = image[ : , : , 1]\n",
    "blue_color = image[ : , : , 2]\n",
    "\n",
    "red_color = red_color.flatten()\n",
    "green_color = green_color.flatten()\n",
    "blue_color = blue_color.flatten()\n",
    "  \n",
    "# Separate Histograms for each color\n",
    "plt.subplot(3, 1, 1) \n",
    "plt.title(\"histogram of Red\") \n",
    "plt.hist(red_color, color=\"red\")  \n",
    "  \n",
    "plt.subplot(3, 1, 2) \n",
    "plt.title(\"histogram of Green\") \n",
    "plt.hist(green_color, color=\"green\") \n",
    "  \n",
    "plt.subplot(3, 1, 3) \n",
    "plt.title(\"histogram of Blue\") \n",
    "plt.hist(blue_color, color=\"blue\")\n",
    "  \n",
    "# for clear view \n",
    "plt.tight_layout() \n",
    "plt.show() \n",
    "  \n",
    "# combined histogram \n",
    "plt.title(\"Histogram of all RGB Colors\") \n",
    "plt.hist(red_color, color=\"red\") \n",
    "plt.hist(green_color, color=\"green\")\n",
    "plt.hist(blue_color, color=\"blue\")  \n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the Python ‘shape’ command indicates that this is a 3D matrix (the greyscale\n",
    "image was a single layer 2D matrix). The color 3D maxtix has three layers (channels), and it's represented\n",
    "in what's known as an RGB format. The letters in RGB refer to 'Red', 'Green', and 'Blue'. The rows and\n",
    "columns contain information on how much of each specific color is contained at each pixel. The first\n",
    "two dimensions tell us that the image is composed of 480 × 320 = 153600 pixels per layer of the image\n",
    "(i.e., for each color).\n",
    "\n",
    "Each layer in the matrix (the third dimension) represents a separate color - one layer each for R, G, and\n",
    "B. As shown above, the RGB color model is an additive model in which red, green, and blue are combined\n",
    "in various ways to reproduce other colors. At each displayed pixel, the information contained in\n",
    "the 3D matrix provides the information on how much of each primary color is applied at each pixel. Depending on your field and software, the RGB values are scaled from 0 to 1 or from 0 to 255. In this courseware, the RGB values are often scaled from 0 to 1, but sometimes 0 to 255. If the range is 0 to 255, a value of 0 indicates no blue (most of the tree), and a value of 255 indicates the most blue (pants of course!). \n",
    "\n",
    "By the way, if you use 8 bits to store red, 8 to store green, and 8 to store blue, then you'll use 24 bits for each pixel, and you'll be able to store any of over 16 million colors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>DSP.04.T2.c) Taking about RBG images</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the above information again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_color = image[ : , : , 0]\n",
    "green_color = image[ : , : , 1]\n",
    "blue_color = image[ : , : , 2]\n",
    "\n",
    "red_color = red_color.flatten()\n",
    "green_color = green_color.flatten()\n",
    "blue_color = blue_color.flatten()\n",
    "  \n",
    "# Separate Histograms for each color\n",
    "plt.subplot(3, 1, 1) \n",
    "plt.title(\"histogram of Red\") \n",
    "plt.hist(red_color, color=\"red\")  \n",
    "  \n",
    "plt.subplot(3, 1, 2) \n",
    "plt.title(\"histogram of Green\") \n",
    "plt.hist(green_color, color=\"green\") \n",
    "  \n",
    "plt.subplot(3, 1, 3) \n",
    "plt.title(\"histogram of Blue\") \n",
    "plt.hist(blue_color, color=\"blue\")\n",
    "  \n",
    "# for clear view \n",
    "plt.tight_layout() \n",
    "plt.show() \n",
    "  \n",
    "# combined histogram \n",
    "plt.title(\"Histogram of all RGB Colors\") \n",
    "plt.hist(red_color, color=\"red\") \n",
    "plt.hist(green_color, color=\"green\")\n",
    "plt.hist(blue_color, color=\"blue\")  \n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also see that image is represented here as a 480 X 320 X 3 array, with each pixel represented as\n",
    "an array of {r,g,b,} triples. Because the red, green, and blue information is individually represented,\n",
    "each component can be separately viewed.\n",
    "\n",
    "Here are just the red values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redimage = image[ : , : , 0]\n",
    "redimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the displayed pixels shows how much red is added to the composite image. A value of 0 indicates\n",
    "no red (e.g., the shadows). A value of 255 indicates the most red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the green values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greenimage = image[ : , : , 1]\n",
    "greenimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the displayed pixels shows how much green is added to the composite image. A value of 0\n",
    "indicates no green (shoes). A value of 255 indicates the most green (leaves in tree)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the blue values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blueimage = image[ : , : , 2]\n",
    "blueimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the displayed pixels shows how much blue is added to the composite image. A value of 0\n",
    "indicates no blue (most of the tree). A value of 255 (or 1) indicates the most blue (pants of course!).\n",
    "The three primary colors are combined to produce a single image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spend a moment examining how the primary colors are combined to create the displayed image. Notice, for example, that the sky is made\n",
    "from both green and blue. Notice that the yellow shirt is made by combining red and green."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>DSP.04.T2.d) Filtering a Color Image</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier in this Tutorial, with a greyscale image, the kernel was convolved with a single 2D matrix of values representing the image.\n",
    "A RGB image represents the image using three separate matrices. As such, some decisions need to be\n",
    "made. Should the kernel be convolved with all three matrices (equivalently, a 3D matrix)? With just the red matrix? Just the blue\n",
    "matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolve a kernel only with the matrix containing the red information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([[1/25, 1/25, 1/25, 1/25, 1/25],\n",
    "                  [1/25, 1/25, 1/25, 1/25, 1/25],\n",
    "                  [1/25, 1/25, 1/25, 1/25, 1/25],\n",
    "                  [1/25, 1/25, 1/25, 1/25, 1/25],\n",
    "                  [1/25, 1/25, 1/25, 1/25, 1/25]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire image can be thought of as being represented as a 3D matrix of values. The rows and\n",
    "columns contain information on how much of each color is applied at each pixel in the image. Three 2D\n",
    "layers provide information about each color (one layer each for R, G, and B). Apply the kernel to the\n",
    "layer containing information about red coloring by grabbing the first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "                 \n",
    "redimage_filtered = np.round(signal.convolve2d(redimage,kernel,boundary='symm', mode='same'))\n",
    "\n",
    "make_imshow(redimage)\n",
    "plt.show()\n",
    "\n",
    "make_imshow(redimage_filtered)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same for the green layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "                 \n",
    "greenimage_filtered = np.round(signal.convolve2d(greenimage,kernel,boundary='symm', mode='same'))\n",
    "\n",
    "make_imshow(greenimage)\n",
    "plt.show()\n",
    "\n",
    "make_imshow(greenimage_filtered)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same for the blue layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "                 \n",
    "blueimage_filtered = np.round(signal.convolve2d(blueimage,kernel,boundary='symm', mode='same'))\n",
    "\n",
    "make_imshow(blueimage)\n",
    "plt.show()\n",
    "\n",
    "make_imshow(blueimage_filtered)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at the composite image with the filtered red, green, and blue components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filtered = np.zeros((480, 320, 3), 'uint8')\n",
    "image_filtered[...,0] = redimage_filtered\n",
    "image_filtered[...,1] = greenimage_filtered\n",
    "image_filtered[...,2] = blueimage_filtered\n",
    "\n",
    "make_imshow_color(image)\n",
    "plt.show()\n",
    "\n",
    "make_imshow_color(image_filtered)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the 'Give it a Try' sections of this lesson, you'll see what the image looks like when you filter just one of the primary\n",
    "colors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
